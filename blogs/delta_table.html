<!DOCTYPE html>
<html lang="en">
<head>
<!-- Google tag (gtag.js) -->
<script async="" src="https://www.googletagmanager.com/gtag/js?id=G-6R7KD1FNMR"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-6R7KD1FNMR');
</script>

<!-- Google tag (gtag.js) -->
<script async="" src="https://www.googletagmanager.com/gtag/js?id=G-6R7KD1FNMR"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-6R7KD1FNMR');
</script>
<meta charset="utf-8"/>
<meta content="width=device-width, initial-scale=1.0" name="viewport"/><meta content="Docutils 0.18.1: http://docutils.sourceforge.net/" name="generator"/>
<title>Exploring Delta Lake’s Powerful Features — Byambalogy</title>
<script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "light";
  </script>
<!-- Loaded before other Sphinx assets -->
<link href="../_static/styles/theme.css?digest=e353d410970836974a52" rel="stylesheet"/>
<link href="../_static/styles/bootstrap.css?digest=e353d410970836974a52" rel="stylesheet"/>
<link href="../_static/styles/pydata-sphinx-theme.css?digest=e353d410970836974a52" rel="stylesheet"/>
<link href="../_static/vendor/fontawesome/6.1.2/css/all.min.css?digest=e353d410970836974a52" rel="stylesheet"/>
<link as="font" crossorigin="" href="../_static/vendor/fontawesome/6.1.2/webfonts/fa-solid-900.woff2" rel="preload" type="font/woff2"/>
<link as="font" crossorigin="" href="../_static/vendor/fontawesome/6.1.2/webfonts/fa-brands-400.woff2" rel="preload" type="font/woff2"/>
<link as="font" crossorigin="" href="../_static/vendor/fontawesome/6.1.2/webfonts/fa-regular-400.woff2" rel="preload" type="font/woff2"/>
<link href="../_static/pygments.css" rel="stylesheet" type="text/css"/>
<link href="../_static/styles/sphinx-book-theme.css?digest=14f4ca6b54d191a8c7657f6c759bf11a5fb86285" rel="stylesheet" type="text/css"/>
<link href="../_static/togglebutton.css" rel="stylesheet" type="text/css"/>
<link href="../_static/copybutton.css" rel="stylesheet" type="text/css"/>
<link href="../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" rel="stylesheet" type="text/css"/>
<link href="../_static/sphinx-thebe.css" rel="stylesheet" type="text/css"/>
<link href="../_static/design-style.4045f2051d55cab465a707391d5b2007.min.css" rel="stylesheet" type="text/css"/>
<!-- Pre-loaded scripts that we'll load fully later -->
<link as="script" href="../_static/scripts/bootstrap.js?digest=e353d410970836974a52" rel="preload"/>
<link as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=e353d410970836974a52" rel="preload"/>
<script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
<script src="../_static/jquery.js"></script>
<script src="../_static/underscore.js"></script>
<script src="../_static/_sphinx_javascript_frameworks_compat.js"></script>
<script src="../_static/doctools.js"></script>
<script src="../_static/clipboard.min.js"></script>
<script src="../_static/copybutton.js"></script>
<script src="../_static/scripts/sphinx-book-theme.js?digest=5a5c038af52cf7bc1a1ec88eea08e6366ee68824"></script>
<script>let toggleHintShow = 'Click to show';</script>
<script>let toggleHintHide = 'Click to hide';</script>
<script>let toggleOpenOnPrint = 'true';</script>
<script src="../_static/togglebutton.js"></script>
<script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
<script src="../_static/design-tabs.js"></script>
<script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
<script async="async" src="../_static/sphinx-thebe.js"></script>
<script>DOCUMENTATION_OPTIONS.pagename = 'blogs/delta_table';</script>
<link href="../genindex.html" rel="index" title="Index"/>
<link href="../search.html" rel="search" title="Search"/>
<link href="big_data.html" rel="next" title="Harnessing the Power of Big Data: A Modern Marvel"/>
<link href="wealth.html" rel="prev" title="The Art of Leveraging Specific Knowledge"/>
<meta content="width=device-width, initial-scale=1" name="viewport"/>
<meta content="en" name="docsearch:language"/>
</head>
<body data-bs-root-margin="0px 0px -60%" data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-default-mode="" data-offset="180">
<a class="skip-link" href="#main-content">Skip to main content</a>
<input class="sidebar-toggle" id="__primary" name="__primary" type="checkbox"/>
<label class="overlay overlay-primary" for="__primary"></label>
<input class="sidebar-toggle" id="__secondary" name="__secondary" type="checkbox"/>
<label class="overlay overlay-secondary" for="__secondary"></label>
<div class="search-button__wrapper">
<div class="search-button__overlay"></div>
<div class="search-button__search-container">
<form action="../search.html" class="bd-search d-flex align-items-center" method="get">
<i class="fa-solid fa-magnifying-glass"></i>
<input aria-label="Search this book..." autocapitalize="off" autocomplete="off" autocorrect="off" class="form-control" id="search-input" name="q" placeholder="Search this book..." spellcheck="false" type="search"/>
<span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
</div>
<nav class="bd-header navbar navbar-expand-lg bd-navbar">
</nav>
<div class="bd-container">
<div class="bd-container__inner bd-page-width">
<div class="bd-sidebar-primary bd-sidebar">
<div class="sidebar-header-items sidebar-primary__section">
</div>
<div class="sidebar-primary-items__start sidebar-primary__section">
<div class="sidebar-primary-item">
<a class="navbar-brand logo" href="../landing.html">
<img alt="Logo image" class="logo__image only-light" src="../_static/logo.png"/>
<script>document.write(`<img src="../_static/logo.png" class="logo__image only-dark" alt="Logo image"/>`);</script>
</a></div>
<div class="sidebar-primary-item"><nav aria-label="Main" class="bd-links" id="bd-docs-nav">
<div class="bd-toc-item navbar-nav active">
<ul class="nav bd-sidenav bd-sidenav__home-link">
<li class="toctree-l1">
<a class="reference internal" href="../landing.html">
                    About this web
                </a>
</li>
</ul>
<ul class="current nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="../courses/courses.html">Courses</a><input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-1"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../courses/introduction.html">Python Courses for beginners</a></li>
<li class="toctree-l2"><a class="reference internal" href="../courses/table_content.html">1. Introduction to Python</a></li>
<li class="toctree-l2"><a class="reference internal" href="../courses/study_guide_2.html">2. Python Data Types</a></li>
<li class="toctree-l2"><a class="reference internal" href="../courses/study_guide_3.html">3. Control Flow</a></li>
<li class="toctree-l2"><a class="reference internal" href="../courses/study_guide_4.html">4. Python Functions</a></li>
<li class="toctree-l2"><a class="reference internal" href="../courses/study_guide_5.html">5. Lists, Tuples, Dictionary, and Sets</a></li>
<li class="toctree-l2"><a class="reference internal" href="../courses/study_guide_6.html">6. String</a></li>
<li class="toctree-l2"><a class="reference internal" href="../courses/simple_flask_app.html">7. Create a Simple Flask App</a></li>
<li class="toctree-l2"><a class="reference internal" href="../courses/update_simple_flask_app.html">Update Flask App with more functions</a></li>
</ul>
</li>
<li class="toctree-l1 current active has-children"><a class="reference internal" href="blogs.html">Blogs</a><input checked="" class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-2"><i class="fa-solid fa-chevron-down"></i></label><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="wealth.html">The Art of Leveraging Specific Knowledge</a></li>
<li class="toctree-l2 current active"><a class="current reference internal" href="#">Exploring Delta Lake’s Powerful Features</a></li>
<li class="toctree-l2"><a class="reference internal" href="big_data.html">Harnessing the Power of Big Data: A Modern Marvel</a></li>
<li class="toctree-l2"><a class="reference internal" href="cloud_services.html">A Overview of Azure, Google Cloud, and AWS</a></li>
<li class="toctree-l2"><a class="reference internal" href="memory_trick.html">Artful Memory Hacks</a></li>
<li class="toctree-l2"><a class="reference internal" href="managed_unmanaged.html">Memorizing Complex Documentation: A Tale of Databricks Tables and Storytelling</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../ebook/tests.html">Databricks</a><input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-3"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../ebook/test_1.html">Questions</a></li>
<li class="toctree-l2"><a class="reference internal" href="../ebook/answers_1.html">Correct Answers</a></li>
<li class="toctree-l2"><a class="reference internal" href="../ebook/explaination_1.html">Explanations</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../mongol/main.html">Монгол</a><input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-4"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../mongol/blog_1.html">Databricks гэж юу?</a></li>
<li class="toctree-l2"><a class="reference internal" href="../mongol/blog_2.html">Дата дата л гэнэ яг юу юм бэ?</a></li>
</ul>
</li>
</ul>
</div>
</nav></div>
</div>
<div class="sidebar-primary-items__end sidebar-primary__section">
</div>
<div id="rtd-footer-container"></div>
</div>
<main class="bd-main" id="main-content">
<div class="sbt-scroll-pixel-helper"></div>
<div class="bd-content">
<div class="bd-article-container">
<div class="bd-header-article">
<div class="header-article-items header-article__inner">
<div class="header-article-items__start">
<div class="header-article-item"><label class="sidebar-toggle primary-toggle btn btn-sm" data-bs-placement="bottom" data-bs-toggle="tooltip" for="__primary" title="Toggle primary sidebar">
<span class="fa-solid fa-bars"></span>
</label></div>
</div>
<div class="header-article-items__end">
<div class="header-article-item">
<div class="article-header-buttons">
<div class="dropdown dropdown-source-buttons">
<button aria-expanded="false" aria-label="Source repositories" class="btn dropdown-toggle" data-bs-toggle="dropdown" type="button">
<i class="fab fa-github"></i>
</button>
<ul class="dropdown-menu">
<li><a class="btn btn-sm btn-source-repository-button dropdown-item" data-bs-placement="left" data-bs-toggle="tooltip" href="https://github.com/byambaa1982/python_cources_for_beginers" target="_blank" title="Source repository">
<span class="btn__icon-container">
<i class="fab fa-github"></i>
</span>
<span class="btn__text-container">Repository</span>
</a>
</li>
<li><a class="btn btn-sm btn-source-issues-button dropdown-item" data-bs-placement="left" data-bs-toggle="tooltip" href="https://github.com/byambaa1982/python_cources_for_beginers/issues/new?title=Issue%20on%20page%20%2Fblogs/delta_table.html&amp;body=Your%20issue%20content%20here." target="_blank" title="Open an issue">
<span class="btn__icon-container">
<i class="fas fa-lightbulb"></i>
</span>
<span class="btn__text-container">Open issue</span>
</a>
</li>
</ul>
</div>
<div class="dropdown dropdown-download-buttons">
<button aria-expanded="false" aria-label="Download this page" class="btn dropdown-toggle" data-bs-toggle="dropdown" type="button">
<i class="fas fa-download"></i>
</button>
<ul class="dropdown-menu">
<li><a class="btn btn-sm btn-download-source-button dropdown-item" data-bs-placement="left" data-bs-toggle="tooltip" href="../_sources/blogs/delta_table.md" target="_blank" title="Download source file">
<span class="btn__icon-container">
<i class="fas fa-file"></i>
</span>
<span class="btn__text-container">.md</span>
</a>
</li>
<li>
<button class="btn btn-sm btn-download-pdf-button dropdown-item" data-bs-placement="left" data-bs-toggle="tooltip" onclick="window.print()" title="Print to PDF">
<span class="btn__icon-container">
<i class="fas fa-file-pdf"></i>
</span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
</ul>
</div>
<button class="btn btn-sm btn-fullscreen-button" data-bs-placement="bottom" data-bs-toggle="tooltip" onclick="toggleFullScreen()" title="Fullscreen mode">
<span class="btn__icon-container">
<i class="fas fa-expand"></i>
</span>
</button>
<script>
document.write(`
  <button class="theme-switch-button btn btn-sm btn-outline-primary navbar-btn rounded-circle" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="theme-switch" data-mode="light"><i class="fa-solid fa-sun"></i></span>
    <span class="theme-switch" data-mode="dark"><i class="fa-solid fa-moon"></i></span>
    <span class="theme-switch" data-mode="auto"><i class="fa-solid fa-circle-half-stroke"></i></span>
  </button>
`);
</script>
<script>
document.write(`
  <button class="btn btn-sm navbar-btn search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
  </button>
`);
</script>
<label class="sidebar-toggle secondary-toggle btn btn-sm" data-bs-placement="bottom" data-bs-toggle="tooltip" for="__secondary" title="Toggle secondary sidebar">
<span class="fa-solid fa-list"></span>
</label>
</div></div>
</div>
</div>
</div>
<div class="onlyprint" id="jb-print-docs-body">
<h1>Exploring Delta Lake’s Powerful Features</h1>
<!-- Table of contents -->
<div id="print-main-content">
<div id="jb-print-toc">
<div>
<h2> Contents </h2>
</div>
<nav aria-label="Page">
<ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#key-features-of-delta-lake-include">Key features of Delta Lake include:</a></li>
</ul>
</nav>
</div>
</div>
</div>
<div id="searchbox"></div>
<article class="bd-article" role="main">
<section class="tex2jax_ignore mathjax_ignore" id="exploring-delta-lake-s-powerful-features">
<h1>Exploring Delta Lake’s Powerful Features<a class="headerlink" href="#exploring-delta-lake-s-powerful-features" title="Permalink to this heading">#</a></h1>
<p>Delta Lake is an open-source storage layer that brings ACID (Atomicity, Consistency, Isolation, Durability) transactions to Apache Spark and big data workloads. Delta Lake is designed to rectify many of the shortcomings of the traditional data lakes and big data file systems which lack the reliability and data consistency features required for handling complex data transformations and analytics.</p>
<section id="key-features-of-delta-lake-include">
<h2>Key features of Delta Lake include:<a class="headerlink" href="#key-features-of-delta-lake-include" title="Permalink to this heading">#</a></h2>
<ol class="arabic simple">
<li><p><code class="docutils literal notranslate"><span class="pre">ACID</span> <span class="pre">Transactions</span></code>: As mentioned, it brings ACID transactions to your data lakes. This ensures reliability and consistency of data even in the event of failures.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">Schema</span> <span class="pre">Enforcement</span> <span class="pre">and</span> <span class="pre">Evolution</span></code>: Delta Lake enforces schema on write, preventing bad data from causing inconsistencies. It also supports schema evolution, letting you add, change, or remove columns seamlessly.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">Audit</span> <span class="pre">History</span></code>: It provides a detailed commit history, which allows for version control, rollbacks, and full audits.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">Scalability</span> <span class="pre">and</span> <span class="pre">Performance</span></code>: Delta Lake scales to handle petabytes of data, and offers improved read and write performance by utilizing techniques like data skipping and Z-ordering (a type of data clustering).</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">Integration</span></code>: Since Delta Lake is fully compatible with Apache Spark API, it can be easily incorporated into existing Spark jobs. It also integrates with other data tools in the ecosystem.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">Time</span> <span class="pre">Travel</span></code>: Delta Lake allows you to access older versions of data, enabling rollbacks, reproducing experiments and reports, and auditing.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">Unified</span> <span class="pre">Batch</span> <span class="pre">and</span> <span class="pre">Streaming</span> <span class="pre">Source</span> <span class="pre">and</span> <span class="pre">Sink</span></code>: A table in Delta Lake is both a batch table, as well as a streaming source and sink. Streaming data ingest, batch historic backfill, and interactive queries all just work out of the box.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">Support</span> <span class="pre">for</span> <span class="pre">Deletes,</span> <span class="pre">Updates,</span> <span class="pre">and</span> <span class="pre">Merges</span></code>: Through Databricks, Delta Lake supports delete, update, and merge operations, which allows building complex data pipelines.</p></li>
</ol>
<p>Delta Lake provides several optimization techniques to speed up query performance on Delta tables. Some of these include:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">Compaction</span> <span class="pre">(Bin-Packing)</span></code>: Over time, as you modify data in your Delta Lake table, you may end up with a large number of small files. Compaction is the process of combining these small files into larger ones, which can improve the speed of read queries and reduce the metadata overhead.</p></li>
</ul>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">pyspark.sql</span> <span class="kn">import</span> <span class="n">SparkSession</span>
<span class="kn">from</span> <span class="nn">delta.tables</span> <span class="kn">import</span> <span class="n">DeltaTable</span>

<span class="c1"># Create a SparkSession</span>
<span class="n">spark</span> <span class="o">=</span> <span class="n">SparkSession</span><span class="o">.</span><span class="n">builder</span> \
    <span class="o">.</span><span class="n">appName</span><span class="p">(</span><span class="s2">"Compaction Example"</span><span class="p">)</span> \
    <span class="o">.</span><span class="n">getOrCreate</span><span class="p">()</span>

<span class="c1"># Create a DataFrame</span>
<span class="n">data</span> <span class="o">=</span> <span class="p">[(</span><span class="s2">"Alice"</span><span class="p">,</span> <span class="s2">"Sales"</span><span class="p">,</span> <span class="mi">5000</span><span class="p">),</span> 
        <span class="p">(</span><span class="s2">"Bob"</span><span class="p">,</span> <span class="s2">"Marketing"</span><span class="p">,</span> <span class="mi">4000</span><span class="p">),</span> 
        <span class="p">(</span><span class="s2">"Charlie"</span><span class="p">,</span> <span class="s2">"Sales"</span><span class="p">,</span> <span class="mi">6000</span><span class="p">),</span> 
        <span class="p">(</span><span class="s2">"Dave"</span><span class="p">,</span> <span class="s2">"Marketing"</span><span class="p">,</span> <span class="mi">3000</span><span class="p">)]</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">createDataFrame</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="p">[</span><span class="s2">"Name"</span><span class="p">,</span> <span class="s2">"Department"</span><span class="p">,</span> <span class="s2">"Salary"</span><span class="p">])</span>
<span class="n">df</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

<span class="o">+-------+----------+------+</span>
<span class="o">|</span>   <span class="n">Name</span><span class="o">|</span><span class="n">Department</span><span class="o">|</span><span class="n">Salary</span><span class="o">|</span>
<span class="o">+-------+----------+------+</span>
<span class="o">|</span>  <span class="n">Alice</span><span class="o">|</span>     <span class="n">Sales</span><span class="o">|</span>  <span class="mi">5000</span><span class="o">|</span>
<span class="o">|</span>    <span class="n">Bob</span><span class="o">|</span> <span class="n">Marketing</span><span class="o">|</span>  <span class="mi">4000</span><span class="o">|</span>
<span class="o">|</span><span class="n">Charlie</span><span class="o">|</span>     <span class="n">Sales</span><span class="o">|</span>  <span class="mi">6000</span><span class="o">|</span>
<span class="o">|</span>   <span class="n">Dave</span><span class="o">|</span> <span class="n">Marketing</span><span class="o">|</span>  <span class="mi">3000</span><span class="o">|</span>
<span class="o">+-------+----------+------+</span>

<span class="c1"># Write the DataFrame to a Delta table</span>
<span class="n">df</span><span class="o">.</span><span class="n">write</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="s2">"delta"</span><span class="p">)</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="s2">"/tmp/delta_table"</span><span class="p">)</span>

<span class="c1"># Convert the saved data to a DeltaTable</span>
<span class="n">deltaTable</span> <span class="o">=</span> <span class="n">DeltaTable</span><span class="o">.</span><span class="n">forPath</span><span class="p">(</span><span class="n">spark</span><span class="p">,</span> <span class="s2">"/tmp/delta_table"</span><span class="p">)</span>

<span class="c1"># Optimize the table layout (compaction/bin-packing)</span>
<span class="n">deltaTable</span><span class="o">.</span><span class="n">optimize</span><span class="p">()</span>

<span class="c1"># Now the data has been compacted into fewer files.</span>

</pre></div>
</div>
<p>In this example:</p>
<ol class="arabic simple">
<li><p>We first create a DataFrame with some simple data and write it to a Delta table.</p></li>
<li><p>We then use the optimize() function on the DeltaTable object. This function coalesces small files into larger ones.</p></li>
</ol>
<p>It’s important to note that while this is a simplified example, the real benefits of compaction come when working with larger datasets. The compaction process can significantly improve the speed of queries by reducing the amount of data that needs to be read and the number of files that need to be managed.</p>
<p>However, compaction is a resource-intensive operation, so it should be used judiciously and typically during periods of low load. Delta Lake provides the option to compact only a subset of data using the ‘OPTIMIZE WHERE’ command, allowing more granular control over the compaction process.</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">Partitioning</span></code>: Partitioning breaks data into discrete buckets based on a particular column or set of columns. This can significantly improve query performance as it allows Delta Lake to skip reading unnecessary data. For instance, if your table has a date column, you could partition the data by date, so queries for a specific date only read data from that particular partition.</p></li>
</ul>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">df</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">createDataFrame</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="p">[</span><span class="s2">"Name"</span><span class="p">,</span> <span class="s2">"Department"</span><span class="p">,</span> <span class="s2">"Salary"</span><span class="p">])</span>

<span class="c1"># Write the DataFrame to a Delta table, partitioned by Department</span>
<span class="n">df</span><span class="o">.</span><span class="n">write</span><span class="o">.</span><span class="n">partitionBy</span><span class="p">(</span><span class="s2">"Department"</span><span class="p">)</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="s2">"delta"</span><span class="p">)</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="s2">"/tmp/delta_table"</span><span class="p">)</span>

<span class="c1"># Now, when you query the table filtering by the "Department", Delta Lake will only read the necessary partition.</span>
<span class="n">result</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">read</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="s2">"delta"</span><span class="p">)</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s2">"/tmp/delta_table"</span><span class="p">)</span><span class="o">.</span><span class="n">filter</span><span class="p">(</span><span class="s2">"Department = 'Sales'"</span><span class="p">)</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
<p>In this example:</p>
<ol class="arabic simple">
<li><p>We first create a DataFrame with some simple data.</p></li>
<li><p>Then, we write this DataFrame to a Delta table using the write.partitionBy() function. This creates a new partition for each unique value in the “Department” column.</p></li>
<li><p>Finally, when we run a query filtering by the “Department” column, Delta Lake only has to read the data in the corresponding partition, skipping the rest.</p></li>
</ol>
<p>Partitioning can be a very effective optimization strategy, but it’s important to choose the right column for partitioning. If you choose a column with too many unique values, you might end up with many small partitions, which can decrease performance due to an overhead of managing many small files. On the other hand, if the column has too few unique values, the benefit of partition pruning may be limited. A column with moderate cardinality that is frequently used in queries is often a good choice.</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">Z-Ordering</span> <span class="pre">(Multi-dimensional</span> <span class="pre">clustering)</span></code>: This is a technique that co-locates related information in the same set of files. Z-Ordering can improve the performance of queries that filter by a specific column (or set of columns).</p></li>
</ul>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span>
<span class="c1"># Create a DataFrame</span>
<span class="n">data</span> <span class="o">=</span> <span class="p">[(</span><span class="s2">"Alice"</span><span class="p">,</span> <span class="mi">25</span><span class="p">),</span> <span class="p">(</span><span class="s2">"Bob"</span><span class="p">,</span> <span class="mi">30</span><span class="p">),</span> <span class="p">(</span><span class="s2">"Charlie"</span><span class="p">,</span> <span class="mi">35</span><span class="p">),</span> <span class="p">(</span><span class="s2">"Dave"</span><span class="p">,</span> <span class="mi">40</span><span class="p">)]</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">createDataFrame</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="p">[</span><span class="s2">"Name"</span><span class="p">,</span> <span class="s2">"Age"</span><span class="p">])</span>

<span class="c1"># Write the DataFrame to a Delta table</span>
<span class="n">df</span><span class="o">.</span><span class="n">write</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="s2">"delta"</span><span class="p">)</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="s2">"/tmp/delta_table"</span><span class="p">)</span>

<span class="c1"># Convert the saved data to a DeltaTable</span>
<span class="n">deltaTable</span> <span class="o">=</span> <span class="n">DeltaTable</span><span class="o">.</span><span class="n">forPath</span><span class="p">(</span><span class="n">spark</span><span class="p">,</span> <span class="s2">"/tmp/delta_table"</span><span class="p">)</span>

<span class="c1"># Run a query and Spark will use data skipping if possible</span>
<span class="n">result</span> <span class="o">=</span> <span class="n">deltaTable</span><span class="o">.</span><span class="n">toDF</span><span class="p">()</span><span class="o">.</span><span class="n">filter</span><span class="p">(</span><span class="s2">"Age &gt; 30"</span><span class="p">)</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="o">+-------+---+</span>
<span class="o">|</span>   <span class="n">Name</span><span class="o">|</span><span class="n">Age</span><span class="o">|</span>
<span class="o">+-------+---+</span>
<span class="o">|</span>   <span class="n">Dave</span><span class="o">|</span> <span class="mi">40</span><span class="o">|</span>
<span class="o">|</span><span class="n">Charlie</span><span class="o">|</span> <span class="mi">35</span><span class="o">|</span>
<span class="o">+-------+---+</span>
</pre></div>
</div>
<p>In this example:</p>
<ol class="arabic simple">
<li><p>We first create a DataFrame with some simple data and write it to a Delta table.</p></li>
<li><p>We then use the zorderBy() function to optimize the layout of the data in the Delta table. This clusters the data based on the “Department” column.</p></li>
<li><p>Finally, when we run a query filtering by the “Department” column, Delta Lake has to read fewer files because the data for each department is co-located in the same set of files.</p></li>
</ol>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">Data</span> <span class="pre">Skipping</span></code>: Delta Lake collects statistics about the data in each file when writing into a table. When querying, Delta Lake can use these statistics to skip unnecessary data. For instance, if a file’s maximum and minimum values for a certain column don’t satisfy a filter condition, that whole file can be skipped.</p></li>
</ul>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Write the DataFrame to a Delta table</span>
<span class="n">df</span><span class="o">.</span><span class="n">write</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="s2">"delta"</span><span class="p">)</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="s2">"/tmp/delta_table"</span><span class="p">)</span>

<span class="c1"># Convert the saved data to a DeltaTable</span>
<span class="n">deltaTable</span> <span class="o">=</span> <span class="n">DeltaTable</span><span class="o">.</span><span class="n">forPath</span><span class="p">(</span><span class="n">spark</span><span class="p">,</span> <span class="s2">"/tmp/delta_table"</span><span class="p">)</span>

<span class="c1"># Run a query and Spark will use data skipping if possible</span>
<span class="n">result</span> <span class="o">=</span> <span class="n">deltaTable</span><span class="o">.</span><span class="n">toDF</span><span class="p">()</span><span class="o">.</span><span class="n">filter</span><span class="p">(</span><span class="s2">"Age &gt; 30"</span><span class="p">)</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

<span class="o">+-------+---+</span>
<span class="o">|</span>   <span class="n">Name</span><span class="o">|</span><span class="n">Age</span><span class="o">|</span>
<span class="o">+-------+---+</span>
<span class="o">|</span>   <span class="n">Dave</span><span class="o">|</span> <span class="mi">40</span><span class="o">|</span>
<span class="o">|</span><span class="n">Charlie</span><span class="o">|</span> <span class="mi">35</span><span class="o">|</span>
<span class="o">+-------+---+</span>
</pre></div>
</div>
<p>In this code:</p>
<ol class="arabic simple">
<li><p>We first import the necessary modules and create a SparkSession.</p></li>
<li><p>We then create a DataFrame with some simple data and write it to a Delta table.</p></li>
<li><p>We convert the saved data to a DeltaTable.</p></li>
<li><p>We run a query that filters for rows where “Age &gt; 30”.</p></li>
</ol>
<p>For this query, if the Delta Lake statistics show that a file’s data for the “Age” column is all less than or equal to 30, then that entire file can be skipped, thus potentially improving the speed of the query.</p>
<p>Please note that this is a very simple example and the actual performance benefit of data skipping might not be noticeable here due to the small size of the data. The advantage of data skipping becomes more apparent with larger datasets where there is a more significant cost to reading unnecessary data.</p>
<p>Also, keep in mind that Delta Lake automatically handles the data skipping internally and there’s no special syntax or configuration required from the user side to take advantage of this feature.</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">Caching</span></code>: Delta Lake and Databricks provide sophisticated caching mechanisms to keep frequently accessed data in memory. This can greatly accelerate query performance.</p></li>
</ul>
<p>In PySpark, you can use the persist() function to cache a DataFrame or Dataset. Here is an example:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">pyspark.sql</span> <span class="kn">import</span> <span class="n">SparkSession</span>

<span class="c1"># Create a SparkSession</span>
<span class="n">spark</span> <span class="o">=</span> <span class="n">SparkSession</span><span class="o">.</span><span class="n">builder</span> \
    <span class="o">.</span><span class="n">appName</span><span class="p">(</span><span class="s2">"Caching Example"</span><span class="p">)</span> \
    <span class="o">.</span><span class="n">getOrCreate</span><span class="p">()</span>

<span class="c1"># Create a DataFrame</span>
<span class="n">data</span> <span class="o">=</span> <span class="p">[(</span><span class="s2">"Alice"</span><span class="p">,</span> <span class="s2">"Sales"</span><span class="p">,</span> <span class="mi">5000</span><span class="p">),</span> 
        <span class="p">(</span><span class="s2">"Bob"</span><span class="p">,</span> <span class="s2">"Marketing"</span><span class="p">,</span> <span class="mi">4000</span><span class="p">),</span> 
        <span class="p">(</span><span class="s2">"Charlie"</span><span class="p">,</span> <span class="s2">"Sales"</span><span class="p">,</span> <span class="mi">6000</span><span class="p">),</span> 
        <span class="p">(</span><span class="s2">"Dave"</span><span class="p">,</span> <span class="s2">"Marketing"</span><span class="p">,</span> <span class="mi">3000</span><span class="p">)]</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">createDataFrame</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="p">[</span><span class="s2">"Name"</span><span class="p">,</span> <span class="s2">"Department"</span><span class="p">,</span> <span class="s2">"Salary"</span><span class="p">])</span>
<span class="n">df</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

<span class="o">+-------+----------+------+</span>
<span class="o">|</span>   <span class="n">Name</span><span class="o">|</span><span class="n">Department</span><span class="o">|</span><span class="n">Salary</span><span class="o">|</span>
<span class="o">+-------+----------+------+</span>
<span class="o">|</span>  <span class="n">Alice</span><span class="o">|</span>     <span class="n">Sales</span><span class="o">|</span>  <span class="mi">5000</span><span class="o">|</span>
<span class="o">|</span>    <span class="n">Bob</span><span class="o">|</span> <span class="n">Marketing</span><span class="o">|</span>  <span class="mi">4000</span><span class="o">|</span>
<span class="o">|</span><span class="n">Charlie</span><span class="o">|</span>     <span class="n">Sales</span><span class="o">|</span>  <span class="mi">6000</span><span class="o">|</span>
<span class="o">|</span>   <span class="n">Dave</span><span class="o">|</span> <span class="n">Marketing</span><span class="o">|</span>  <span class="mi">3000</span><span class="o">|</span>
<span class="o">+-------+----------+------+</span>

<span class="c1"># Cache the DataFrame</span>
<span class="n">df</span><span class="o">.</span><span class="n">persist</span><span class="p">()</span>

<span class="c1"># Now, subsequent actions on this DataFrame will be faster as the data is cached in memory.</span>
<span class="n">result</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">filter</span><span class="p">(</span><span class="s2">"Department = 'Sales'"</span><span class="p">)</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

</pre></div>
</div>
<p>In this example, we create a DataFrame, and then use the <code class="docutils literal notranslate"><span class="pre">persist()</span></code> function to cache it in memory. Subsequent actions on this DataFrame will be faster because Spark can read the data from memory, instead of re-computing the DataFrame from the original source.</p>
<p>It’s important to note that caching consumes memory, and there is a trade-off between the memory used for caching and other operations. If you cache too much data, and Spark runs out of memory, it will have to evict some cached data using a Least Recently Used (LRU) policy. Also, caching doesn’t make sense for all workloads, particularly if you’re only performing a single action on the data. Caching is most effective for iterative workloads, where the same data is processed multiple times.</p>
<p>In addition to the <code class="docutils literal notranslate"><span class="pre">persist()</span></code> function, which caches data in memory and allows it to spill to disk if there is not enough memory, Spark also provides the <code class="docutils literal notranslate"><span class="pre">cache()</span></code> function, which is a synonym for <code class="docutils literal notranslate"><span class="pre">persist()</span></code>. You can also specify a storage level to <code class="docutils literal notranslate"><span class="pre">persist()</span></code>, to control whether the data should be stored in memory, on disk, or serialized, etc. To remove data from cache, you can use the <code class="docutils literal notranslate"><span class="pre">unpersist()</span></code> function.</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">Indexing</span></code>: While not a built-in feature of Delta Lake as of my knowledge cutoff in September 2021, indexing is a common optimization technique in databases. Some third-party solutions offer indexing for Delta Lake, which can speed up queries by creating and maintaining a secondary lookup data structure.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">Delta</span> <span class="pre">Lake's</span> <span class="pre">Time</span> <span class="pre">Travel</span> <span class="pre">Feature</span></code>: Although this feature is not directly aimed at optimizing performance, it allows you to access and query previous versions of the table. This can be helpful in understanding how data changes over time and for auditing changes, reproducing experiments, rolling back changes, and so on.</p></li>
</ul>
<p>Here’s an example of how you can use Time Travel in PySpark:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">pyspark.sql</span> <span class="kn">import</span> <span class="n">SparkSession</span>
<span class="kn">from</span> <span class="nn">delta.tables</span> <span class="kn">import</span> <span class="n">DeltaTable</span>

<span class="c1"># Create a SparkSession</span>
<span class="n">spark</span> <span class="o">=</span> <span class="n">SparkSession</span><span class="o">.</span><span class="n">builder</span> \
    <span class="o">.</span><span class="n">appName</span><span class="p">(</span><span class="s2">"Time Travel Example"</span><span class="p">)</span> \
    <span class="o">.</span><span class="n">getOrCreate</span><span class="p">()</span>

<span class="c1"># Create a DataFrame</span>
<span class="n">data</span> <span class="o">=</span> <span class="p">[(</span><span class="s2">"Alice"</span><span class="p">,</span> <span class="s2">"Sales"</span><span class="p">,</span> <span class="mi">5000</span><span class="p">),</span> 
        <span class="p">(</span><span class="s2">"Bob"</span><span class="p">,</span> <span class="s2">"Marketing"</span><span class="p">,</span> <span class="mi">4000</span><span class="p">),</span> 
        <span class="p">(</span><span class="s2">"Charlie"</span><span class="p">,</span> <span class="s2">"Sales"</span><span class="p">,</span> <span class="mi">6000</span><span class="p">),</span> 
        <span class="p">(</span><span class="s2">"Dave"</span><span class="p">,</span> <span class="s2">"Marketing"</span><span class="p">,</span> <span class="mi">3000</span><span class="p">)]</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">createDataFrame</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="p">[</span><span class="s2">"Name"</span><span class="p">,</span> <span class="s2">"Department"</span><span class="p">,</span> <span class="s2">"Salary"</span><span class="p">])</span>

<span class="c1"># Write the DataFrame to a Delta table</span>
<span class="n">df</span><span class="o">.</span><span class="n">write</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="s2">"delta"</span><span class="p">)</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="s2">"/tmp/delta_table"</span><span class="p">)</span>

<span class="c1"># Now let's update the DataFrame</span>
<span class="n">updated_data</span> <span class="o">=</span> <span class="p">[(</span><span class="s2">"Alice"</span><span class="p">,</span> <span class="s2">"Sales"</span><span class="p">,</span> <span class="mi">5500</span><span class="p">),</span> 
                <span class="p">(</span><span class="s2">"Bob"</span><span class="p">,</span> <span class="s2">"Marketing"</span><span class="p">,</span> <span class="mi">4500</span><span class="p">),</span> 
                <span class="p">(</span><span class="s2">"Charlie"</span><span class="p">,</span> <span class="s2">"Sales"</span><span class="p">,</span> <span class="mi">6500</span><span class="p">),</span> 
                <span class="p">(</span><span class="s2">"Dave"</span><span class="p">,</span> <span class="s2">"Marketing"</span><span class="p">,</span> <span class="mi">3500</span><span class="p">)]</span>
<span class="n">updated_df</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">createDataFrame</span><span class="p">(</span><span class="n">updated_data</span><span class="p">,</span> <span class="p">[</span><span class="s2">"Name"</span><span class="p">,</span> <span class="s2">"Department"</span><span class="p">,</span> <span class="s2">"Salary"</span><span class="p">])</span>

<span class="c1"># Overwrite the original data</span>
<span class="n">updated_df</span><span class="o">.</span><span class="n">write</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="s2">"delta"</span><span class="p">)</span><span class="o">.</span><span class="n">mode</span><span class="p">(</span><span class="s2">"overwrite"</span><span class="p">)</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="s2">"/tmp/delta_table"</span><span class="p">)</span>

<span class="c1"># Now we can use Time Travel to access the previous version of the table</span>
<span class="n">previous_version</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">read</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="s2">"delta"</span><span class="p">)</span><span class="o">.</span><span class="n">option</span><span class="p">(</span><span class="s2">"versionAsOf"</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s2">"/tmp/delta_table"</span><span class="p">)</span>
<span class="n">previous_version</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

<span class="o">+-------+----------+------+</span>
<span class="o">|</span>   <span class="n">Name</span><span class="o">|</span><span class="n">Department</span><span class="o">|</span><span class="n">Salary</span><span class="o">|</span>
<span class="o">+-------+----------+------+</span>
<span class="o">|</span>  <span class="n">Alice</span><span class="o">|</span>     <span class="n">Sales</span><span class="o">|</span>  <span class="mi">5000</span><span class="o">|</span>
<span class="o">|</span>    <span class="n">Bob</span><span class="o">|</span> <span class="n">Marketing</span><span class="o">|</span>  <span class="mi">4000</span><span class="o">|</span>
<span class="o">|</span><span class="n">Charlie</span><span class="o">|</span>     <span class="n">Sales</span><span class="o">|</span>  <span class="mi">6000</span><span class="o">|</span>
<span class="o">|</span>   <span class="n">Dave</span><span class="o">|</span> <span class="n">Marketing</span><span class="o">|</span>  <span class="mi">3000</span><span class="o">|</span>
<span class="o">+-------+----------+------+</span>

<span class="c1"># And the current version</span>
<span class="n">current_version</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">read</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="s2">"delta"</span><span class="p">)</span><span class="o">.</span><span class="n">option</span><span class="p">(</span><span class="s2">"versionAsOf"</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s2">"/tmp/delta_table"</span><span class="p">)</span>
<span class="n">current_version</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
<span class="o">+-------+----------+------+</span>
<span class="o">|</span>   <span class="n">Name</span><span class="o">|</span><span class="n">Department</span><span class="o">|</span><span class="n">Salary</span><span class="o">|</span>
<span class="o">+-------+----------+------+</span>
<span class="o">|</span>  <span class="n">Alice</span><span class="o">|</span>     <span class="n">Sales</span><span class="o">|</span>  <span class="mi">5500</span><span class="o">|</span>
<span class="o">|</span>    <span class="n">Bob</span><span class="o">|</span> <span class="n">Marketing</span><span class="o">|</span>  <span class="mi">4500</span><span class="o">|</span>
<span class="o">|</span><span class="n">Charlie</span><span class="o">|</span>     <span class="n">Sales</span><span class="o">|</span>  <span class="mi">6500</span><span class="o">|</span>
<span class="o">|</span>   <span class="n">Dave</span><span class="o">|</span> <span class="n">Marketing</span><span class="o">|</span>  <span class="mi">3500</span><span class="o">|</span>
<span class="o">+-------+----------+------+</span>
</pre></div>
</div>
<p>Remember to also leverage the power of Spark’s Catalyst Optimizer, which works under the hood to optimize the execution of your queries.</p>
</section>
</section>
<script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./blogs"
        },
        predefinedOutput: true
    }
    </script>
<script>kernelName = 'python3'</script>
</article>
<footer class="bd-footer-article">
<div class="footer-article-items footer-article__inner">
<div class="footer-article-item"><!-- Previous / next buttons -->
<div class="prev-next-area">
<a class="left-prev" href="wealth.html" title="previous page">
<i class="fa-solid fa-angle-left"></i>
<div class="prev-next-info">
<p class="prev-next-subtitle">previous</p>
<p class="prev-next-title">The Art of Leveraging Specific Knowledge</p>
</div>
</a>
<a class="right-next" href="big_data.html" title="next page">
<div class="prev-next-info">
<p class="prev-next-subtitle">next</p>
<p class="prev-next-title">Harnessing the Power of Big Data: A Modern Marvel</p>
</div>
<i class="fa-solid fa-angle-right"></i>
</a>
</div></div>
</div>
</footer>
</div>
<div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">
<div class="sidebar-secondary-item">
<div class="page-toc tocsection onthispage">
<i class="fa-solid fa-list"></i> Contents
  </div>
<nav class="bd-toc-nav page-toc">
<ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#key-features-of-delta-lake-include">Key features of Delta Lake include:</a></li>
</ul>
</nav></div>
</div></div>
</div>
<footer class="bd-footer-content">
<div class="bd-footer-content__inner container">
<div class="footer-item">
<p class="component-author">
By Byamba Enkhbat
</p>
</div>
<div class="footer-item">
<p class="copyright">
    
      © Copyright 2022.
      <br/>
</p>
</div>
<div class="footer-item">
</div>
<div class="footer-item">
</div>
</div>
</footer>
</main>
</div>
</div>
<!-- Scripts loaded after <body> so the DOM is not blocked -->
<script src="../_static/scripts/bootstrap.js?digest=e353d410970836974a52"></script>
<script src="../_static/scripts/pydata-sphinx-theme.js?digest=e353d410970836974a52"></script>
<footer class="bd-footer">
</footer>
</body>
</html>