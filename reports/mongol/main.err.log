Traceback (most recent call last):
  File "C:\Python311\Lib\site-packages\jupyter_cache\executors\utils.py", line 58, in single_nb_execution
    executenb(
  File "C:\Python311\Lib\site-packages\nbclient\client.py", line 1304, in execute
    return NotebookClient(nb=nb, resources=resources, km=km, **kwargs).execute()
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Python311\Lib\site-packages\jupyter_core\utils\__init__.py", line 166, in wrapped
    return loop.run_until_complete(inner)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Python311\Lib\asyncio\base_events.py", line 653, in run_until_complete
    return future.result()
           ^^^^^^^^^^^^^^^
  File "C:\Python311\Lib\site-packages\nbclient\client.py", line 705, in async_execute
    await self.async_execute_cell(
  File "C:\Python311\Lib\site-packages\nbclient\client.py", line 1020, in async_execute_cell
    await self._check_raise_for_error(cell, cell_index, exec_reply)
  File "C:\Python311\Lib\site-packages\nbclient\client.py", line 914, in _check_raise_for_error
    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)
nbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:
------------------
import snscrape.modules.twitter as sntwitter
import pandas

# Creating list to append tweet data 
tweets_list1 = []

# Using TwitterSearchScraper to scrape data and append tweets to list
for i,tweet in enumerate(sntwitter.TwitterSearchScraper('from:coderjs').get_items()): #declare a username 
    if i>10: #number of tweets you want to scrape
        break
    tweets_list1.append([tweet.date, tweet.id, tweet.content, tweet.user.username]) #declare the attributes to be returned
    
# Creating a dataframe from the tweets list above 
tweets_df1 = pd.DataFrame(tweets_list1, columns=['Datetime', 'Tweet Id', 'Text', 'Username'])
------------------

[1;31m---------------------------------------------------------------------------[0m
[1;31mScraperException[0m                          Traceback (most recent call last)
Cell [1;32mIn[5], line 8[0m
[0;32m      5[0m tweets_list1 [38;5;241m=[39m []
[0;32m      7[0m [38;5;66;03m# Using TwitterSearchScraper to scrape data and append tweets to list[39;00m
[1;32m----> 8[0m [38;5;28;01mfor[39;00m i,tweet [38;5;129;01min[39;00m [38;5;28menumerate[39m(sntwitter[38;5;241m.[39mTwitterSearchScraper([38;5;124m'[39m[38;5;124mfrom:coderjs[39m[38;5;124m'[39m)[38;5;241m.[39mget_items()): [38;5;66;03m#declare a username [39;00m
[0;32m      9[0m     [38;5;28;01mif[39;00m i[38;5;241m>[39m[38;5;241m10[39m: [38;5;66;03m#number of tweets you want to scrape[39;00m
[0;32m     10[0m         [38;5;28;01mbreak[39;00m

File [1;32mC:\Python311\Lib\site-packages\snscrape\modules\twitter.py:1763[0m, in [0;36mTwitterSearchScraper.get_items[1;34m(self)[0m
[0;32m   1760[0m params [38;5;241m=[39m {[38;5;124m'[39m[38;5;124mvariables[39m[38;5;124m'[39m: variables, [38;5;124m'[39m[38;5;124mfeatures[39m[38;5;124m'[39m: features}
[0;32m   1761[0m paginationParams [38;5;241m=[39m {[38;5;124m'[39m[38;5;124mvariables[39m[38;5;124m'[39m: paginationVariables, [38;5;124m'[39m[38;5;124mfeatures[39m[38;5;124m'[39m: features}
[1;32m-> 1763[0m [38;5;28;01mfor[39;00m obj [38;5;129;01min[39;00m [38;5;28mself[39m[38;5;241m.[39m_iter_api_data([38;5;124m'[39m[38;5;124mhttps://twitter.com/i/api/graphql/7jT5GT59P8IFjgxwqnEdQw/SearchTimeline[39m[38;5;124m'[39m, _TwitterAPIType[38;5;241m.[39mGRAPHQL, params, paginationParams, cursor [38;5;241m=[39m [38;5;28mself[39m[38;5;241m.[39m_cursor, instructionsPath [38;5;241m=[39m [[38;5;124m'[39m[38;5;124mdata[39m[38;5;124m'[39m, [38;5;124m'[39m[38;5;124msearch_by_raw_query[39m[38;5;124m'[39m, [38;5;124m'[39m[38;5;124msearch_timeline[39m[38;5;124m'[39m, [38;5;124m'[39m[38;5;124mtimeline[39m[38;5;124m'[39m, [38;5;124m'[39m[38;5;124minstructions[39m[38;5;124m'[39m]):
[0;32m   1764[0m 	[38;5;28;01myield from[39;00m [38;5;28mself[39m[38;5;241m.[39m_graphql_timeline_instructions_to_tweets(obj[[38;5;124m'[39m[38;5;124mdata[39m[38;5;124m'[39m][[38;5;124m'[39m[38;5;124msearch_by_raw_query[39m[38;5;124m'[39m][[38;5;124m'[39m[38;5;124msearch_timeline[39m[38;5;124m'[39m][[38;5;124m'[39m[38;5;124mtimeline[39m[38;5;124m'[39m][[38;5;124m'[39m[38;5;124minstructions[39m[38;5;124m'[39m])

File [1;32mC:\Python311\Lib\site-packages\snscrape\modules\twitter.py:915[0m, in [0;36m_TwitterAPIScraper._iter_api_data[1;34m(self, endpoint, apiType, params, paginationParams, cursor, direction, instructionsPath)[0m
[0;32m    913[0m [38;5;28;01mwhile[39;00m [38;5;28;01mTrue[39;00m:
[0;32m    914[0m 	_logger[38;5;241m.[39minfo([38;5;124mf[39m[38;5;124m'[39m[38;5;124mRetrieving scroll page [39m[38;5;132;01m{[39;00mcursor[38;5;132;01m}[39;00m[38;5;124m'[39m)
[1;32m--> 915[0m 	obj [38;5;241m=[39m [38;5;28;43mself[39;49m[38;5;241;43m.[39;49m[43m_get_api_data[49m[43m([49m[43mendpoint[49m[43m,[49m[43m [49m[43mapiType[49m[43m,[49m[43m [49m[43mreqParams[49m[43m,[49m[43m [49m[43minstructionsPath[49m[43m [49m[38;5;241;43m=[39;49m[43m [49m[43minstructionsPath[49m[43m)[49m
[0;32m    916[0m 	[38;5;28;01myield[39;00m obj
[0;32m    918[0m 	[38;5;66;03m# No data format test, just a hard and loud crash if anything's wrong :-)[39;00m

File [1;32mC:\Python311\Lib\site-packages\snscrape\modules\twitter.py:886[0m, in [0;36m_TwitterAPIScraper._get_api_data[1;34m(self, endpoint, apiType, params, instructionsPath)[0m
[0;32m    884[0m [38;5;28;01mif[39;00m apiType [38;5;129;01mis[39;00m _TwitterAPIType[38;5;241m.[39mGRAPHQL:
[0;32m    885[0m 	params [38;5;241m=[39m urllib[38;5;241m.[39mparse[38;5;241m.[39murlencode({k: json[38;5;241m.[39mdumps(v, separators [38;5;241m=[39m ([38;5;124m'[39m[38;5;124m,[39m[38;5;124m'[39m, [38;5;124m'[39m[38;5;124m:[39m[38;5;124m'[39m)) [38;5;28;01mfor[39;00m k, v [38;5;129;01min[39;00m params[38;5;241m.[39mitems()}, quote_via [38;5;241m=[39m urllib[38;5;241m.[39mparse[38;5;241m.[39mquote)
[1;32m--> 886[0m r [38;5;241m=[39m [38;5;28;43mself[39;49m[38;5;241;43m.[39;49m[43m_get[49m[43m([49m[43mendpoint[49m[43m,[49m[43m [49m[43mparams[49m[43m [49m[38;5;241;43m=[39;49m[43m [49m[43mparams[49m[43m,[49m[43m [49m[43mheaders[49m[43m [49m[38;5;241;43m=[39;49m[43m [49m[38;5;28;43mself[39;49m[38;5;241;43m.[39;49m[43m_apiHeaders[49m[43m,[49m[43m [49m[43mresponseOkCallback[49m[43m [49m[38;5;241;43m=[39;49m[43m [49m[43mfunctools[49m[38;5;241;43m.[39;49m[43mpartial[49m[43m([49m[38;5;28;43mself[39;49m[38;5;241;43m.[39;49m[43m_check_api_response[49m[43m,[49m[43m [49m[43mapiType[49m[43m [49m[38;5;241;43m=[39;49m[43m [49m[43mapiType[49m[43m,[49m[43m [49m[43minstructionsPath[49m[43m [49m[38;5;241;43m=[39;49m[43m [49m[43minstructionsPath[49m[43m)[49m[43m)[49m
[0;32m    887[0m [38;5;28;01mreturn[39;00m r[38;5;241m.[39m_snscrapeObj

File [1;32mC:\Python311\Lib\site-packages\snscrape\base.py:275[0m, in [0;36mScraper._get[1;34m(self, *args, **kwargs)[0m
[0;32m    274[0m [38;5;28;01mdef[39;00m [38;5;21m_get[39m([38;5;28mself[39m, [38;5;241m*[39margs, [38;5;241m*[39m[38;5;241m*[39mkwargs):
[1;32m--> 275[0m 	[38;5;28;01mreturn[39;00m [38;5;28;43mself[39;49m[38;5;241;43m.[39;49m[43m_request[49m[43m([49m[38;5;124;43m'[39;49m[38;5;124;43mGET[39;49m[38;5;124;43m'[39;49m[43m,[49m[43m [49m[38;5;241;43m*[39;49m[43margs[49m[43m,[49m[43m [49m[38;5;241;43m*[39;49m[38;5;241;43m*[39;49m[43mkwargs[49m[43m)[49m

File [1;32mC:\Python311\Lib\site-packages\snscrape\base.py:271[0m, in [0;36mScraper._request[1;34m(self, method, url, params, data, headers, timeout, responseOkCallback, allowRedirects, proxies)[0m
[0;32m    269[0m 	_logger[38;5;241m.[39mfatal(msg)
[0;32m    270[0m 	_logger[38;5;241m.[39mfatal([38;5;124mf[39m[38;5;124m'[39m[38;5;124mErrors: [39m[38;5;132;01m{[39;00m[38;5;124m"[39m[38;5;124m, [39m[38;5;124m"[39m[38;5;241m.[39mjoin(errors)[38;5;132;01m}[39;00m[38;5;124m'[39m)
[1;32m--> 271[0m 	[38;5;28;01mraise[39;00m ScraperException(msg)
[0;32m    272[0m [38;5;28;01mraise[39;00m [38;5;167;01mRuntimeError[39;00m([38;5;124m'[39m[38;5;124mReached unreachable code[39m[38;5;124m'[39m)

[1;31mScraperException[0m: 4 requests to https://twitter.com/i/api/graphql/7jT5GT59P8IFjgxwqnEdQw/SearchTimeline?variables=%7B%22rawQuery%22%3A%22from%3Acoderjs%22%2C%22count%22%3A20%2C%22product%22%3A%22Latest%22%2C%22withDownvotePerspective%22%3Afalse%2C%22withReactionsMetadata%22%3Afalse%2C%22withReactionsPerspective%22%3Afalse%7D&features=%7B%22rweb_lists_timeline_redesign_enabled%22%3Afalse%2C%22blue_business_profile_image_shape_enabled%22%3Afalse%2C%22responsive_web_graphql_exclude_directive_enabled%22%3Atrue%2C%22verified_phone_label_enabled%22%3Afalse%2C%22creator_subscriptions_tweet_preview_api_enabled%22%3Afalse%2C%22responsive_web_graphql_timeline_navigation_enabled%22%3Atrue%2C%22responsive_web_graphql_skip_user_profile_image_extensions_enabled%22%3Afalse%2C%22tweetypie_unmention_optimization_enabled%22%3Atrue%2C%22vibe_api_enabled%22%3Atrue%2C%22responsive_web_edit_tweet_api_enabled%22%3Atrue%2C%22graphql_is_translatable_rweb_tweet_is_translatable_enabled%22%3Atrue%2C%22view_counts_everywhere_api_enabled%22%3Atrue%2C%22longform_notetweets_consumption_enabled%22%3Atrue%2C%22tweet_awards_web_tipping_enabled%22%3Afalse%2C%22freedom_of_speech_not_reach_fetch_enabled%22%3Afalse%2C%22standardized_nudges_misinfo%22%3Atrue%2C%22tweet_with_visibility_results_prefer_gql_limited_actions_policy_enabled%22%3Afalse%2C%22interactive_text_enabled%22%3Atrue%2C%22responsive_web_text_conversations_enabled%22%3Afalse%2C%22longform_notetweets_rich_text_read_enabled%22%3Afalse%2C%22longform_notetweets_inline_media_enabled%22%3Afalse%2C%22responsive_web_enhance_cards_enabled%22%3Afalse%2C%22responsive_web_twitter_blue_verified_badge_is_enabled%22%3Atrue%7D failed, giving up.
ScraperException: 4 requests to https://twitter.com/i/api/graphql/7jT5GT59P8IFjgxwqnEdQw/SearchTimeline?variables=%7B%22rawQuery%22%3A%22from%3Acoderjs%22%2C%22count%22%3A20%2C%22product%22%3A%22Latest%22%2C%22withDownvotePerspective%22%3Afalse%2C%22withReactionsMetadata%22%3Afalse%2C%22withReactionsPerspective%22%3Afalse%7D&features=%7B%22rweb_lists_timeline_redesign_enabled%22%3Afalse%2C%22blue_business_profile_image_shape_enabled%22%3Afalse%2C%22responsive_web_graphql_exclude_directive_enabled%22%3Atrue%2C%22verified_phone_label_enabled%22%3Afalse%2C%22creator_subscriptions_tweet_preview_api_enabled%22%3Afalse%2C%22responsive_web_graphql_timeline_navigation_enabled%22%3Atrue%2C%22responsive_web_graphql_skip_user_profile_image_extensions_enabled%22%3Afalse%2C%22tweetypie_unmention_optimization_enabled%22%3Atrue%2C%22vibe_api_enabled%22%3Atrue%2C%22responsive_web_edit_tweet_api_enabled%22%3Atrue%2C%22graphql_is_translatable_rweb_tweet_is_translatable_enabled%22%3Atrue%2C%22view_counts_everywhere_api_enabled%22%3Atrue%2C%22longform_notetweets_consumption_enabled%22%3Atrue%2C%22tweet_awards_web_tipping_enabled%22%3Afalse%2C%22freedom_of_speech_not_reach_fetch_enabled%22%3Afalse%2C%22standardized_nudges_misinfo%22%3Atrue%2C%22tweet_with_visibility_results_prefer_gql_limited_actions_policy_enabled%22%3Afalse%2C%22interactive_text_enabled%22%3Atrue%2C%22responsive_web_text_conversations_enabled%22%3Afalse%2C%22longform_notetweets_rich_text_read_enabled%22%3Afalse%2C%22longform_notetweets_inline_media_enabled%22%3Afalse%2C%22responsive_web_enhance_cards_enabled%22%3Afalse%2C%22responsive_web_twitter_blue_verified_badge_is_enabled%22%3Atrue%7D failed, giving up.

