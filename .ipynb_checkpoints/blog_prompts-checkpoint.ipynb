{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7393532b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "import tiktoken\n",
    "import json\n",
    "from PIL import Image\n",
    "import io\n",
    "import base64\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "import PyPDF2\n",
    "\n",
    "\n",
    "\n",
    "_ = load_dotenv(find_dotenv()) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8ef11af",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ad9b2fd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the API key from a JSON file\n",
    "with open('config.json', 'r') as file:\n",
    "    config = json.load(file)\n",
    "    api_key = config['openai_api_key']\n",
    "\n",
    "openai.api_key = str(api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b5a5fed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_compress_encode_image(image_path, output_size=(300, 100), quality=60):\n",
    "    # Resize and compress the image\n",
    "    with Image.open(image_path) as img:\n",
    "        img = img.resize(output_size, Image.Resampling.LANCZOS)\n",
    "        buffer = io.BytesIO()\n",
    "        img.save(buffer, format=\"JPEG\", quality=quality)\n",
    "        buffer.seek(0)\n",
    "        encoded_image = base64.b64encode(buffer.read()).decode()\n",
    "    return encoded_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c63e970b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_completion(prompt, model=\"gpt-4-1106-preview\"):\n",
    "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=0, # this is the degree of randomness of the model's output \n",
    "    )\n",
    "    return response.choices[0].message[\"content\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ef1d3586",
   "metadata": {},
   "outputs": [],
   "source": [
    "def send_image_query_to_openai(encoded_image):\n",
    "    # Prepare the chat message payload with the encoded image\n",
    "    payload = {\n",
    "        \"model\": \"gpt-4-vision-preview\",  \n",
    "        \"messages\": [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": [\n",
    "                    {\"type\": \"text\", \"text\": \"What’s in this image?\"},\n",
    "                    {\n",
    "                        \"type\": \"image_url\",\n",
    "                        \"image_url\": {\n",
    "                            \"url\": f\"data:image/jpeg;base64,{encoded_image}\"\n",
    "                        },\n",
    "                    },\n",
    "                ],\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "\n",
    "    # Send the request to the API\n",
    "    response = openai.ChatCompletion.create(**payload)\n",
    "\n",
    "    # Return the content of the response\n",
    "    return response.choices[0].message[\"content\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b488299c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_openai_with_image_url(image_url, question=\"What’s in this image?\"):\n",
    "    # Prepare the chat message payload with the image URL\n",
    "    payload = {\n",
    "        \"model\": \"gpt-4-vision-preview\",  \n",
    "        \"messages\": [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": [\n",
    "                    {\"type\": \"text\", \"text\": question},\n",
    "                    {\n",
    "                        \"type\": \"image_url\",\n",
    "                        \"image_url\": {\"url\": image_url},\n",
    "                    },\n",
    "                ],\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "\n",
    "    # Send the request to the API\n",
    "    response = openai.ChatCompletion.create(**payload)\n",
    "    return response.choices[0].message[\"content\"] if 'choices' in response and response.choices else \"No content found\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "201eb58e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_python_file_to_string(file_path):\n",
    "    try:\n",
    "        with open(file_path, 'r', encoding='utf-8') as file:\n",
    "            code_string = file.read()\n",
    "        return code_string\n",
    "    except FileNotFoundError:\n",
    "        return \"File not found.\"\n",
    "    except Exception as e:\n",
    "        return f\"An error occurred: {str(e)}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f2c67f8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def notebook_to_string(file_path):\n",
    "    try:\n",
    "        with open(file_path, 'r', encoding='utf-8') as file:\n",
    "            notebook_content = json.load(file)\n",
    "        return json.dumps(notebook_content, indent=4)  # Convert JSON content to a formatted string\n",
    "    except FileNotFoundError:\n",
    "        return \"File not found: {}\".format(file_path)\n",
    "    except json.JSONDecodeError:\n",
    "        return \"Error decoding JSON from file: {}\".format(file_path)\n",
    "    except Exception as e:\n",
    "        return \"An error occurred: {}\".format(str(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b98db50a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def string_to_notebook(json_string, file_path):\n",
    "    try:\n",
    "        # Parse the JSON string\n",
    "        notebook_content = json.loads(json_string)\n",
    "\n",
    "        # Write the JSON object to an .ipynb file\n",
    "        with open(file_path, 'w', encoding='utf-8') as file:\n",
    "            json.dump(notebook_content, file, indent=4)\n",
    "\n",
    "        return f\"Successfully created notebook: {file_path}\"\n",
    "    except json.JSONDecodeError:\n",
    "        return \"Invalid JSON string\"\n",
    "    except Exception as e:\n",
    "        return f\"An error occurred: {str(e)}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a47272be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def markdown_to_string(file_path):\n",
    "    try:\n",
    "        with open(file_path, 'r', encoding='utf-8') as file:\n",
    "            content = file.read()\n",
    "        return content\n",
    "    except FileNotFoundError:\n",
    "        return f\"File not found: {file_path}\"\n",
    "    except Exception as e:\n",
    "        return f\"An error occurred: {str(e)}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "104423a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def string_to_markdown(content, file_path):\n",
    "    try:\n",
    "        with open(file_path, 'w', encoding='utf-8') as file:\n",
    "            file.write(content)\n",
    "        return f\"Successfully written to {file_path}\"\n",
    "    except Exception as e:\n",
    "        return f\"An error occurred: {str(e)}\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b0789473",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunk_text_by_question(text):\n",
    "    # Split text using a positive lookbehind on the pattern \"### Question X\"\n",
    "    # This keeps the pattern in the resulting list\n",
    "    questions = re.split(r'(?<=\\n### Question \\d+\\n)', text)\n",
    "\n",
    "    # Remove the first empty element if it exists\n",
    "    if questions and questions[0].strip() == '':\n",
    "        questions = questions[1:]\n",
    "\n",
    "    return questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "51f71dda",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def chunk_text_by_question(text):\n",
    "    # Split text on the pattern, but keep the pattern in the result\n",
    "    questions = re.split(r'(\\n### Question \\d+\\n)', text)\n",
    "\n",
    "    # Reattach the split pattern to each chunk\n",
    "    combined_questions = []\n",
    "    for i in range(1, len(questions), 2):\n",
    "        combined_question = questions[i] + questions[i+1]\n",
    "        combined_questions.append(combined_question.strip())\n",
    "\n",
    "    return combined_questions\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a13b2d21",
   "metadata": {},
   "outputs": [],
   "source": [
    "def append_to_markdown(file_path, text_to_append):\n",
    "    try:\n",
    "        with open(file_path, 'a', encoding='utf-8') as file:\n",
    "            file.write(text_to_append)\n",
    "        return f\"Text appended successfully to {file_path}\"\n",
    "    except FileNotFoundError:\n",
    "        return \"File not found.\"\n",
    "    except Exception as e:\n",
    "        return f\"An error occurred: {str(e)}\"\n",
    "\n",
    "# Example usage\n",
    "# file_path = 'test_2.md'  # Replace with your Markdown file path\n",
    "# text_to_append = question_list[29]\n",
    "# result = append_to_markdown(file_path, text_to_append)\n",
    "# print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f1cf3014",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nbformat\n",
    "import os\n",
    "\n",
    "def notebook_to_markdown(notebook_path, markdown_path):\n",
    "    try:\n",
    "        # Read the notebook\n",
    "        with open(notebook_path, 'r', encoding='utf-8') as file:\n",
    "            notebook = nbformat.read(file, as_version=4)\n",
    "\n",
    "        # Process each cell and extract content\n",
    "        markdown_content = []\n",
    "        for cell in notebook.cells:\n",
    "            if cell.cell_type == 'markdown':\n",
    "                # Directly add markdown content\n",
    "                markdown_content.append(''.join(cell.source))\n",
    "            elif cell.cell_type == 'code':\n",
    "                # Add code in Markdown code block format\n",
    "                code_block = '```python\\n' + ''.join(cell.source) + '\\n```'\n",
    "                markdown_content.append(code_block)\n",
    "\n",
    "        # Write content to the markdown file\n",
    "        with open(markdown_path, 'w', encoding='utf-8') as md_file:\n",
    "            md_file.write('\\n'.join(markdown_content))\n",
    "\n",
    "        return f\"Markdown file created successfully: {markdown_path}\"\n",
    "    except FileNotFoundError:\n",
    "        return \"Notebook file not found.\"\n",
    "    except Exception as e:\n",
    "        return f\"An error occurred: {str(e)}\"\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c4f66422",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_compress_encode_image(image_path, output_size=(300, 100), quality=60):\n",
    "    # Resize and compress the image\n",
    "    with Image.open(image_path) as img:\n",
    "        img = img.resize(output_size, Image.Resampling.LANCZOS)\n",
    "        buffer = io.BytesIO()\n",
    "        img.save(buffer, format=\"JPEG\", quality=quality)\n",
    "        buffer.seek(0)\n",
    "        encoded_image = base64.b64encode(buffer.read()).decode()\n",
    "    return encoded_image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c29a5d16",
   "metadata": {},
   "source": [
    "# Actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7b1f2e5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Successfully written to test_1.md'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_file = \"test_1.ipynb\"\n",
    "output_file = \"test_1.md\"\n",
    "content = notebook_to_string(input_file)\n",
    "string_to_markdown(content, output_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4757a62d",
   "metadata": {},
   "source": [
    "# Prompt 1: Create ebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "97419797",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_5_part_2.md\n",
      "test_11_part_2.md\n"
     ]
    }
   ],
   "source": [
    "files = [ \"test_5_part_2.md\"]\n",
    "for i, file in enumerate(files, start=1):\n",
    "    print(file)\n",
    "    content_string = markdown_to_string(file)\n",
    "\n",
    "    prompt = f'''Please read practice exam for the Databricks Certified Data Engineer Associate exam and create \n",
    "    a similar multiple-choice test. However, modify it by changing questions and the correct answers and slightly altering \n",
    "    the knowledge topics.\n",
    "    But if question 5 is lakehouse, then you create a lakehouse question for new question 5, \n",
    "    if question is about data governance question, then create data governance question. \n",
    "    After each question, add correct answers, exam topic (Databricks Lakehouse Platform or ELT with Spark SQL and Python or\n",
    "    Incremental Data Processing or Production Pipelines or Data Governance), and explanation. \n",
    "    I would like the new test to be structured in the same format as the original, and returned to me a markdown format too. \n",
    "    My input json {content_string}'''\n",
    "\n",
    "    completion = get_completion(prompt)\n",
    "    if completion:\n",
    "        output_path = f\"test_11_part_2.md\"\n",
    "        print(output_path)\n",
    "        result = string_to_markdown(completion, output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1404840f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_10_part_1.md\n",
      "test_12_part_1.md\n",
      "test_10_part_2.md\n",
      "test_12_part_2.md\n",
      "test_10_part_3.md\n",
      "test_12_part_3.md\n",
      "test_10_part_4.md\n",
      "test_12_part_4.md\n"
     ]
    }
   ],
   "source": [
    "files = [\"test_10_part_1.md\", \"test_10_part_2.md\", \"test_10_part_3.md\", \"test_10_part_4.md\"]\n",
    "for i, file in enumerate(files, start=1):\n",
    "    print(file)\n",
    "    content_string = markdown_to_string(file)\n",
    "\n",
    "    prompt = f'''Please read practice exam for the Databricks Certified Data Engineer Associate exam and create \n",
    "    a similar multiple-choice test. However, modify it by changing questions and the correct answers and slightly altering \n",
    "    the knowledge topics.\n",
    "    But if question 5 is lakehouse, then you create a lakehouse question for new question 5, \n",
    "    if question is about data governance question, then create data governance question. \n",
    "    After each question, add correct answers, exam topic (Databricks Lakehouse Platform or ELT with Spark SQL and Python or\n",
    "    Incremental Data Processing or Production Pipelines or Data Governance), and explanation. \n",
    "    I would like the new test to be structured in the same format as the original, and returned to me a markdown format too. \n",
    "    My input json {content_string}'''\n",
    "\n",
    "    completion = get_completion(prompt)\n",
    "    if completion:\n",
    "        output_path = f\"test_12_part_{i}.md\"\n",
    "        print(output_path)\n",
    "        result = string_to_markdown(completion, output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "320afa64",
   "metadata": {},
   "source": [
    "# Prompt 2: Test image AI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "abb11561",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The image shows a stylized 3D representation of data visualization models. It\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "encoded_image = resize_compress_encode_image('ai_chart.png')  # Make sure to use your function to get the encoded image\n",
    "response_content = send_image_query_to_openai(encoded_image)\n",
    "print(response_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "239ea7cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"id\": \"chatcmpl-8Vp3uiYFyj6Da6aVQbmwcluWCq2sD\",\n",
      "  \"object\": \"chat.completion\",\n",
      "  \"created\": 1702595142,\n",
      "  \"model\": \"gpt-4-1106-vision-preview\",\n",
      "  \"usage\": {\n",
      "    \"prompt_tokens\": 1118,\n",
      "    \"completion_tokens\": 16,\n",
      "    \"total_tokens\": 1134\n",
      "  },\n",
      "  \"choices\": [\n",
      "    {\n",
      "      \"message\": {\n",
      "        \"role\": \"assistant\",\n",
      "        \"content\": \"The image shows a picturesque natural landscape featuring a wooden boardwalk extending through a lush\"\n",
      "      },\n",
      "      \"finish_details\": {\n",
      "        \"type\": \"max_tokens\"\n",
      "      },\n",
      "      \"index\": 0\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "The image shows a picturesque natural landscape featuring a wooden boardwalk extending through a lush\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "image_url = \"https://upload.wikimedia.org/wikipedia/commons/thumb/d/dd/Gfp-wisconsin-madison-the-nature-boardwalk.jpg/2560px-Gfp-wisconsin-madison-the-nature-boardwalk.jpg\"\n",
    "response_content = query_openai_with_image_url(image_url)\n",
    "print(response_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "15958d3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text_from_pdf(pdf_path):\n",
    "    with open(pdf_path, 'rb') as file:\n",
    "        reader = PyPDF2.PdfReader(file)\n",
    "        text = \"\"\n",
    "        for page in reader.pages:\n",
    "            text += page.extract_text()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7725ffe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_text = extract_text_from_pdf('test_1.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3677d320",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 45 questions listed in your message.\n"
     ]
    }
   ],
   "source": [
    "prompt = f'''\n",
    "How many quesiton are here? {pdf_text}\n",
    "'''\n",
    "completion = get_completion(prompt)\n",
    "if completion:\n",
    "    print(completion)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86aacbe3",
   "metadata": {},
   "source": [
    "# Combine files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "989b6b10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_1_part_*\n",
      "test_2_part_*\n",
      "test_3_part_*\n",
      "test_4_part_*\n",
      "test_5_part_*\n",
      "test_6_part_*\n",
      "test_7_part_*\n",
      "test_8_part_*\n",
      "test_9_part_*\n",
      "test_10_part_*\n",
      "test_11_part_*\n",
      "test_12_part_*\n"
     ]
    }
   ],
   "source": [
    "file_patterns = []\n",
    "for i in range(1, 13):\n",
    "    fname = f'test_{i}_part_*'\n",
    "    print(fname)\n",
    "    file_patterns.append(fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a7985889",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files combined successfully.\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import os\n",
    "\n",
    "# Define the directory where the combined files will be saved\n",
    "output_directory = 'tests'\n",
    "\n",
    "# Create the directory if it does not exist\n",
    "if not os.path.exists(output_directory):\n",
    "    os.makedirs(output_directory)\n",
    "\n",
    "\n",
    "for pattern in file_patterns:\n",
    "    # Find all files matching the pattern\n",
    "    files_to_combine = glob.glob(f'{pattern}.md')\n",
    "\n",
    "    # Sort the files to maintain order\n",
    "    files_to_combine.sort()\n",
    "\n",
    "    # Define the name of the combined file, saved in the 'tests' directory\n",
    "    combined_file_name = os.path.join(output_directory, pattern.split('_part_')[0] + '.md')\n",
    "\n",
    "    # Combine the contents of the files\n",
    "    with open(combined_file_name, 'w', encoding='utf-8') as combined_file:\n",
    "        for file_name in files_to_combine:\n",
    "            with open(file_name, 'r', encoding='utf-8') as file:\n",
    "                # Write the content of each file to the combined file\n",
    "                combined_file.write(file.read() + '\\n')\n",
    "\n",
    "print(\"Files combined successfully.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f315317b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_*\n",
      "test_*\n",
      "test_*\n",
      "test_*\n",
      "test_*\n",
      "test_*\n",
      "test_*\n",
      "test_*\n",
      "test_*\n",
      "test_*\n",
      "test_*\n",
      "test_*\n"
     ]
    }
   ],
   "source": [
    "file_patterns = []\n",
    "for i in range(1, 13):\n",
    "    fname = f'test_*'\n",
    "    print(fname)\n",
    "    file_patterns.append(fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "07254aba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All files in tests have been combined into tests.md.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Define the directory containing the files and the output file name\n",
    "input_directory = 'tests'\n",
    "output_file = 'tests.md'\n",
    "\n",
    "# Create or open the output file\n",
    "with open(output_file, 'w', encoding='utf-8') as outfile:\n",
    "    # Iterate through each file in the specified directory\n",
    "    for filename in os.listdir(input_directory):\n",
    "        filepath = os.path.join(input_directory, filename)\n",
    "        # Check if it's a file, not a directory\n",
    "        if os.path.isfile(filepath):\n",
    "            with open(filepath, 'r', encoding='utf-8') as infile:\n",
    "                # Read the contents of the file and write it to the output file\n",
    "                outfile.write(infile.read() + '\\n')\n",
    "\n",
    "print(f\"All files in {input_directory} have been combined into {output_file}.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e79d11ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An error occurred during conversion: Command '['pandoc', 'tests.md', '-o', 'tests.pdf', '-V', 'geometry:margin=1in', '-V', 'fontsize=10pt', '-V', 'geometry:landscape']' returned non-zero exit status 47.\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "\n",
    "def markdown_to_pdf_pandoc(markdown_file, pdf_file, margin='1in', fontsize='10pt', landscape=False):\n",
    "    try:\n",
    "        command = [\"pandoc\", markdown_file, \"-o\", pdf_file, \"-V\", f\"geometry:margin={margin}\", \"-V\", f\"fontsize={fontsize}\"]\n",
    "        if landscape:\n",
    "            command.extend([\"-V\", \"geometry:landscape\"])\n",
    "        \n",
    "        subprocess.run(command, check=True)\n",
    "\n",
    "        return f\"PDF created successfully: {pdf_file}\"\n",
    "    except FileNotFoundError:\n",
    "        return \"Markdown file not found or Pandoc is not installed.\"\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        return f\"An error occurred during conversion: {str(e)}\"\n",
    "    except Exception as e:\n",
    "        return f\"An error occurred: {str(e)}\"\n",
    "\n",
    "# Example usage\n",
    "markdown_file = 'tests.md'\n",
    "pdf_file = 'tests.pdf'\n",
    "result = markdown_to_pdf_pandoc(markdown_file, pdf_file, landscape=True)  # Change landscape to False if not needed\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4789a234",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
