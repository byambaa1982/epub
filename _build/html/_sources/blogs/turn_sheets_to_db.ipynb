{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a97c5a8c",
   "metadata": {},
   "source": [
    "# Mastering Data Flow: Google Sheets to SQLite via Python"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e7ca762",
   "metadata": {},
   "source": [
    "Google Sheets, while being an exceptional tool for the non-tech savvy, isn't particularly efficient for complex querying. In this guide, I'll demonstrate how just a few lines of Python can harness your Google Sheet as a valuable input for your SQL database. The beauty of this approach is its adaptability; whether it's SQLite, PostgreSQL, MongoDB, or any other database you prefer, you can seamlessly transform and integrate your Google Sheet data with ease."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e51378a",
   "metadata": {},
   "source": [
    "![summit](../images/automation_400_200.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e45c9c7",
   "metadata": {},
   "source": [
    "Here, we'll bridge the worlds of Google Sheets, Pandas, and SQLite to create a seamless data pipeline. Before we dive in, let's understand the tools in our toolkit and the magic behind our data extraction function:\n",
    "\n",
    "1. `pandas (imported as pd)`: Our data manipulation champion! With pd, we can reshape, analyze, and transform our tabular data with ease.\n",
    "\n",
    "2. `json`: It's how we'll talk to Google Sheets. Most authentication credentials for Sheets come in JSON format, and this module helps us handle that.\n",
    "\n",
    "3. `oauth2client & gspread`: Our gateways to Google Sheets. The former authenticates us, and the latter lets us read, write, and navigate our sheets like a pro.\n",
    "\n",
    "4. `sqlite3`: Where our processed data finds a home! SQLite offers a lightweight database solution, perfect for storing and querying our data.\n",
    "\n",
    "5. `datetime & timedelta`: Timekeepers of our script. From calculating durations to stamping records, these modules are essential for any time-related operations.\n",
    "\n",
    "With our tools at the ready, let's dive into creating a robust data flow, turning Google Sheets insights into actionable SQLite data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2a8c9c33",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "from oauth2client.service_account import ServiceAccountCredentials\n",
    "import gspread\n",
    "import sqlite3\n",
    "from datetime import datetime, timedelta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be5c6fc7",
   "metadata": {},
   "source": [
    "## Deep Dive: The Data Extraction Function\n",
    "\n",
    "`get_user_information(sheet_name)`: This utility function serves as our bridge to Google Sheets. Before diving into its mechanics, it's pivotal to have the creds.json file in place. To obtain this file, head to your Google Cloud Console, navigate to the 'Credentials' page within the `APIs & Services` section, and create a service account; once done, you can download its corresponding JSON key. Ensure your Google Sheet is shared with the service account email tied to your creds.json to facilitate seamless authentication and data retrieval. With these preparations, the function selects your desired worksheet, retrieves the data, and elegantly transforms it into a Pandas DataFrame, setting the stage for deeper data operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "144749b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_user_information(sheet_name):\n",
    "  scope = ['https://spreadsheets.google.com/feeds','https://www.googleapis.com/auth/drive']\n",
    "\n",
    "  creds = ServiceAccountCredentials.from_json_keyfile_name('creds.json',scope)\n",
    "\n",
    "  client = gspread.authorize(creds)\n",
    "\n",
    "  industries = client.open(\"quizs\").worksheet(sheet_name)\n",
    "  users = pd.DataFrame(industries.get_all_values())\n",
    "\n",
    "  return users"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4591fcd4",
   "metadata": {},
   "source": [
    "- creds.json\n",
    "\n",
    "```\n",
    "{   \n",
    "\"type\": \"service_account\",   \n",
    "\"project_id\": \"YOUR-PROJECT-ID\",   \n",
    "\"private_key_id\": \"YOUR-PRIVATE-KEY-ID\",  \n",
    "\"private_key\": \"YOUR-PRIVATE-KEY\",  \n",
    "\"client_email\": \"YOUR-SERVICE-ACCOUNT@appspot.gserviceaccount.com\",   \n",
    "\"client_id\": \"CLIENT-ID\",  \n",
    "\"auth_uri\": \"https://accounts.google.com/o/oauth2/auth\",  \n",
    "\"token_uri\": \"https://oauth2.googleapis.com/token\",   \n",
    "\"auth_provider_x509_cert_url\": \"https://www.googleapis.com/oauth2/v1/certs\",   \n",
    "\"client_x509_cert_url\": \"https://www.googleapis.com/robot/v1/metadata/x509/twittersheet-275317%40appspot.gserviceaccount.com\" \n",
    "}\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "697ae78a",
   "metadata": {},
   "source": [
    "## Data Transformation Steps:\n",
    "\n",
    "1. `Fetching Data`: We retrieve data from the worksheet titled \"questions\" using our function.\n",
    "2. `Cleaning and Formatting`: The DataFrame's first row becomes our column headers, which we then drop, ensuring a clean data structure.\n",
    "3. `Timestamping`: A new 'question_created' column gets added, marking each entry with the current date and time.\n",
    "4. `Database Initialization`: We prepare to inject our data into an SQLite database named 'quiz.sqlite3', ensuring our insights find a structured home.\n",
    "\n",
    "With our toolkit and methods detailed, let's dive deep, transforming Google Sheets' insights into structured SQLite datasets. Let the data flow commence!\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f87d6355",
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = get_user_information(\"questions\")\n",
    "questions = questions.rename(columns=questions.iloc[0]).drop(questions.index[0])\n",
    "questions['question_created'] = datetime.now()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9836d9f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>question_text</th>\n",
       "      <th>question_type</th>\n",
       "      <th>question_created</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Which of the following features distinguishes ...</td>\n",
       "      <td>lakehouse</td>\n",
       "      <td>2023-08-26 09:32:30.461600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Which of the following locations hosts the dri...</td>\n",
       "      <td>lakehouse</td>\n",
       "      <td>2023-08-26 09:32:30.461600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>A data architect is designing a data model tha...</td>\n",
       "      <td>lakehouse</td>\n",
       "      <td>2023-08-26 09:32:30.461600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Which of the following describes a scenario in...</td>\n",
       "      <td>lakehouse</td>\n",
       "      <td>2023-08-26 09:32:30.461600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>A data engineer has created a Delta table as p...</td>\n",
       "      <td>lakehouse</td>\n",
       "      <td>2023-08-26 09:32:30.461600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>Two junior data engineers are authoring separa...</td>\n",
       "      <td>lakehouse</td>\n",
       "      <td>2023-08-26 09:32:30.461600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  id                                      question_text question_type   \n",
       "1  1  Which of the following features distinguishes ...     lakehouse  \\\n",
       "2  2  Which of the following locations hosts the dri...     lakehouse   \n",
       "3  3  A data architect is designing a data model tha...     lakehouse   \n",
       "4  4  Which of the following describes a scenario in...     lakehouse   \n",
       "5  5  A data engineer has created a Delta table as p...     lakehouse   \n",
       "6  6  Two junior data engineers are authoring separa...     lakehouse   \n",
       "\n",
       "            question_created  \n",
       "1 2023-08-26 09:32:30.461600  \n",
       "2 2023-08-26 09:32:30.461600  \n",
       "3 2023-08-26 09:32:30.461600  \n",
       "4 2023-08-26 09:32:30.461600  \n",
       "5 2023-08-26 09:32:30.461600  \n",
       "6 2023-08-26 09:32:30.461600  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "be646cdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "db_path = 'quiz.sqlite3'  \n",
    "conn = sqlite3.connect(db_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e50dd17",
   "metadata": {},
   "source": [
    "db_path = 'quiz.sqlite3'  \n",
    "conn = sqlite3.connect(db_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "600f1e50",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "The digital landscape offers a myriad of tools to harness and analyze data. In our journey, we've explored how the synergy between Google Sheets, Pandas, and SQLite provides a formidable arsenal for data enthusiasts and professionals alike. By crafting a seamless pipeline, we've unlocked the potential to transform simple spreadsheet records into structured database entries, ensuring scalability, ease of access, and advanced analytics. Whether you're just starting out or are a seasoned data veteran, integrating these tools into your workflow can usher in a new era of efficiency and insights. As we always say in the data world, the right tools and the right processes make all the difference. Happy data wrangling!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0c2f2f0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
